{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import ast\n",
    "\n",
    "pd.set_option(\"display.max_rows\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnb model with tfidf-word, all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', sep=',', encoding='utf8')\n",
    "test = pd.read_csv('data/test.csv', sep=',', encoding='utf8')\n",
    "n_train = train.shape[0]\n",
    "n_test = test.shape[0]\n",
    "full_set = pd.read_pickle('full_cleaned.pkl')\n",
    "labels = train.columns[2:8].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training classifier on toxic label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 15.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}, cv_score: 0.9550078827130518, train_score: 0.9679276328979506, test_score: 0.9596303256634855\n",
      "Fitting final model and making prediction for submission on toxic label\n",
      "Start training classifier on severe_toxic label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}, cv_score: 0.9789676614405037, train_score: 0.9883241955519528, test_score: 0.9772268899559129\n",
      "Fitting final model and making prediction for submission on severe_toxic label\n",
      "Start training classifier on obscene label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.6, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}, cv_score: 0.9657177130254938, train_score: 0.9733249942525654, test_score: 0.9642367549101658\n",
      "Fitting final model and making prediction for submission on obscene label\n",
      "Start training classifier on threat label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.003}, cv_score: 0.9697533098478018, train_score: 0.9853950030058413, test_score: 0.9615744851084782\n",
      "Fitting final model and making prediction for submission on threat label\n",
      "Start training classifier on insult label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 13.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}, cv_score: 0.9612750237601925, train_score: 0.9712145235929304, test_score: 0.9640399284301722\n",
      "Fitting final model and making prediction for submission on insult label\n",
      "Start training classifier on identity_hate label\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0003}, cv_score: 0.9625447197861673, train_score: 0.9818428366846956, test_score: 0.9723479872212811\n",
      "Fitting final model and making prediction for submission on identity_hate label\n",
      "Wall time: 1h 34min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_mnb_records = pd.DataFrame(index=labels, columns=['best_params', 'cv_score', 'train_score', 'test_score'])\n",
    "word_mnb_full = pd.DataFrame(index=full_set.index, columns=labels)\n",
    "for label in labels:\n",
    "    print('Start training classifier on {} label'.format(label))\n",
    "    x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(full_set.cleaned_text[:n_train], \n",
    "                                                        full_set[label][:n_train], \n",
    "                                                        np.arange(n_train),\n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state=2018,\n",
    "                                                        stratify = full_set[label][:n_train])\n",
    "    word_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "    parameters = {'tfidf__max_df': [0.4, 0.2, 0.15],\\\n",
    "                  'tfidf__min_df': [0.0001, 0.0003, 0.003],\\\n",
    "                  'nb__alpha': [0.6, 0.5, 0.4, 0.2]\n",
    "                 }\n",
    "    word_mnb_cv = GridSearchCV(word_mnb, parameters, n_jobs=-1, scoring = 'roc_auc', verbose=1, cv=5)\n",
    "    word_mnb_cv.fit(x_train, y_train)\n",
    "    word_mnb_records.loc[label,'best_params'] = str(word_mnb_cv.best_params_)\n",
    "    word_mnb_records.loc[label,'cv_score'] = word_mnb_cv.best_score_\n",
    "    word_mnb_records.loc[label, 'train_score'] = metrics.roc_auc_score(y_train, word_mnb_cv.predict_proba(x_train)[:,1])\n",
    "    word_mnb_records.loc[label, 'test_score'] = metrics.roc_auc_score(y_test, word_mnb_cv.predict_proba(x_test)[:,1])\n",
    "    print('Best params: {}, cv_score: {}, train_score: {}, test_score: {}'.format(*word_mnb_records.loc[label]))\n",
    "    word_mnb.set_params(**word_mnb_cv.best_params_)\n",
    "    print('Fitting final model and making prediction for submission on {} label'.format(label))\n",
    "    word_mnb.fit(full_set.cleaned_text[:n_train], full_set[label][:n_train])\n",
    "    word_mnb_full[label] = word_mnb.predict_proba(full_set.cleaned_text)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}\n",
      "{'nb__alpha': 0.2, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
      "{'nb__alpha': 0.6, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
      "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.003}\n",
      "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
      "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0003}\n",
      "               cv_score train_score test_score\n",
      "toxic          0.955008    0.967928    0.95963\n",
      "severe_toxic   0.978968    0.988324   0.977227\n",
      "obscene        0.965718    0.973325   0.964237\n",
      "threat         0.969753    0.985395   0.961574\n",
      "insult         0.961275    0.971215    0.96404\n",
      "identity_hate  0.962545    0.981843   0.972348\n",
      "cv_score       0.965544\n",
      "train_score    0.978005\n",
      "test_score     0.966509\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(*word_mnb_records.best_params, sep='\\n')\n",
    "print(word_mnb_records.iloc[:,1:])\n",
    "print(word_mnb_records.iloc[:,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.6, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.003}\n",
    "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0003}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.955008    0.967928    0.95963\n",
    "severe_toxic   0.978968    0.988324   0.977227\n",
    "obscene        0.965718    0.973325   0.964237\n",
    "threat         0.969753    0.985395   0.961574\n",
    "insult         0.961275    0.971215    0.96404\n",
    "identity_hate  0.962545    0.981843   0.972348\n",
    "cv_score       0.965544\n",
    "train_score    0.978005\n",
    "test_score     0.966509\n",
    "\n",
    "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.5, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.003}\n",
    "{'nb__alpha': 0.4, 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003}\n",
    "{'nb__alpha': 0.2, 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0003}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.955008    0.967928    0.95963\n",
    "severe_toxic   0.978968    0.988324   0.977227\n",
    "obscene         0.96566    0.973624   0.964084\n",
    "threat         0.969753    0.985395   0.961574\n",
    "insult         0.961275    0.971215    0.96404\n",
    "identity_hate  0.962545    0.981843   0.972348\n",
    "cv_score       0.965535\n",
    "train_score    0.978055\n",
    "test_score     0.966484\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_mnb_full.to_csv('data/word_mnb_full.csv',index=False)\n",
    "word_mnb_records.to_csv('data/word_mnb_records.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                  'tfidf__max_df': [0.4, 0.3, 0.2, 0.15],\\\n",
    "                  'tfidf__min_df': [0.0001, 0.0003, 0.001, 0.003],\\\n",
    "                  'nb__alpha': [0.6, 0.5, 0.4, 0.2, 0.1]\n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **create train test sets for stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating out-of-sample predictions on identity_hate label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on insult label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on obscene label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on severe_toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on threat label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_mnb_stack_train = pd.DataFrame(np.zeros((n_train, 6)), columns=labels)\n",
    "word_mnb_stack_test = pd.read_csv('data/word_mnb_full.csv')[n_train:]\n",
    "word_mnb_records = pd.read_csv('data/word_mnb_records.csv')\n",
    "\n",
    "for j,label in enumerate(labels):\n",
    "    print('Start generating out-of-sample predictions on {} label for stacking'.format(label))\n",
    "    skf = list(StratifiedKFold(full_set[label][:n_train], 5))\n",
    "    word_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "    word_mnb.set_params(**ast.literal_eval(word_mnb_records.loc[j, 'best_params']))\n",
    "    for i,(train, test) in enumerate(skf):\n",
    "        print(\"Fold\", i+1)\n",
    "        X_train = full_set.cleaned_text[train]\n",
    "        y_train = full_set[label][train]\n",
    "        X_test = full_set.cleaned_text[test]\n",
    "        y_test = full_set[label][test]\n",
    "        word_mnb.fit(X_train, y_train)\n",
    "        word_mnb_stack_train.iloc[test, j] = word_mnb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.008053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.009322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.056350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.059278</td>\n",
       "      <td>0.060850</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.108738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.004163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.122075</td>\n",
       "      <td>0.101095</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.433457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0.012858</td>\n",
       "      <td>0.056633</td>\n",
       "      <td>0.068233</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.084456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.019894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.018469</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.069172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_hate    insult   obscene  severe_toxic    threat     toxic\n",
       "0            0.000439  0.002457  0.005074      0.000160  0.000229  0.008053\n",
       "1            0.000743  0.002486  0.004467      0.000587  0.000495  0.009322\n",
       "2            0.000044  0.014916  0.014376      0.000809  0.000012  0.056350\n",
       "3            0.000007  0.000025  0.000162      0.000015  0.000013  0.000105\n",
       "4            0.002124  0.059278  0.060850      0.001994  0.000976  0.108738\n",
       "...               ...       ...       ...           ...       ...       ...\n",
       "159566       0.000026  0.000743  0.002093      0.000220  0.000029  0.004163\n",
       "159567       0.002106  0.122075  0.101095      0.003875  0.004834  0.433457\n",
       "159568       0.012858  0.056633  0.068233      0.000805  0.005588  0.084456\n",
       "159569       0.000147  0.006671  0.006905      0.000442  0.000060  0.019894\n",
       "159570       0.000111  0.020474  0.018469      0.002092  0.000090  0.069172\n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_mnb_stack_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_mnb_stack_train.to_csv('data/word_mnb_stack_train.csv')\n",
    "word_mnb_stack_test.to_csv('data/word_mnb_stack_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mnb model with tfidf-char, all labels ---very time consuming to fine tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training classifier on toxic label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9438663617735209, train_score: 0.9513621686238408, test_score: 0.947215629356778\n",
      "Fitting final model and making prediction for submission on toxic label\n",
      "Start training classifier on severe_toxic label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9810017332462886, train_score: 0.9877322633982899, test_score: 0.9796894551550314\n",
      "Fitting final model and making prediction for submission on severe_toxic label\n",
      "Start training classifier on obscene label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 21.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9616746624720707, train_score: 0.9677143459412112, test_score: 0.9615631971260908\n",
      "Fitting final model and making prediction for submission on obscene label\n",
      "Start training classifier on threat label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 21.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9491728837908645, train_score: 0.9793309125622283, test_score: 0.9514403409388522\n",
      "Fitting final model and making prediction for submission on threat label\n",
      "Start training classifier on insult label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9555089673517058, train_score: 0.9635760462895477, test_score: 0.9627183245963734\n",
      "Fitting final model and making prediction for submission on insult label\n",
      "Start training classifier on identity_hate label\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 19.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9625542433104942, train_score: 0.9789429647042994, test_score: 0.970552315777182\n",
      "Fitting final model and making prediction for submission on identity_hate label\n",
      "Wall time: 2h 58min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "char_mnb_records = pd.DataFrame(index=labels, columns=['best_params', 'cv_score', 'train_score', 'test_score'])\n",
    "char_mnb_full = pd.DataFrame(index=full_set.index, columns=labels)\n",
    "for label in labels:\n",
    "    print('Start training classifier on {} label'.format(label))\n",
    "    x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(full_set.cleaned_text[:n_train], \n",
    "                                                        full_set[label][:n_train], \n",
    "                                                        np.arange(n_train),\n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state=2018,\n",
    "                                                        stratify = full_set[label][:n_train])\n",
    "    char_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "    parameters = {'tfidf__analyzer': ['char'],\\\n",
    "              'tfidf__max_df': [0.15, 0.12],\\\n",
    "              'tfidf__min_df': [0.0003],\\\n",
    "              'tfidf__ngram_range': [(1,5)],\\\n",
    "              'tfidf__max_features': [40000],\\\n",
    "              'nb__alpha': [0.4, 0.2]}\n",
    "    char_mnb_cv = GridSearchCV(char_mnb, parameters, n_jobs=-1, scoring = 'roc_auc', verbose=1, cv=3)\n",
    "    char_mnb_cv.fit(x_train, y_train)\n",
    "    char_mnb_records.loc[label,'best_params'] = str(char_mnb_cv.best_params_)\n",
    "    char_mnb_records.loc[label,'cv_score'] = char_mnb_cv.best_score_\n",
    "    char_mnb_records.loc[label, 'train_score'] = metrics.roc_auc_score(y_train, char_mnb_cv.predict_proba(x_train)[:,1])\n",
    "    char_mnb_records.loc[label, 'test_score'] = metrics.roc_auc_score(y_test, char_mnb_cv.predict_proba(x_test)[:,1])\n",
    "    print('Best params: {}, cv_score: {}, train_score: {}, test_score: {}'.format(*char_mnb_records.loc[label]))\n",
    "    char_mnb.set_params(**char_mnb_cv.best_params_)\n",
    "    print('Fitting final model and making prediction for submission on {} label'.format(label))\n",
    "    char_mnb.fit(full_set.cleaned_text[:n_train], full_set[label][:n_train])\n",
    "    char_mnb_full[label] = char_mnb.predict_proba(full_set.cleaned_text)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "               cv_score train_score test_score\n",
      "toxic          0.943866    0.951362   0.947216\n",
      "severe_toxic   0.981002    0.987732   0.979689\n",
      "obscene        0.961675    0.967714   0.961563\n",
      "threat         0.949173    0.979331    0.95144\n",
      "insult         0.955509    0.963576   0.962718\n",
      "identity_hate  0.962554    0.978943   0.970552\n",
      "cv_score       0.958963\n",
      "train_score    0.971443\n",
      "test_score     0.962197\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(*char_mnb_records.best_params, sep='\\n')\n",
    "print(char_mnb_records.iloc[:,1:])\n",
    "print(char_mnb_records.iloc[:,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.12, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.943866    0.951362   0.947216\n",
    "severe_toxic   0.981002    0.987732   0.979689\n",
    "obscene        0.961675    0.967714   0.961563\n",
    "threat         0.949173    0.979331    0.95144\n",
    "insult         0.955509    0.963576   0.962718\n",
    "identity_hate  0.962554    0.978943   0.970552\n",
    "cv_score       0.958963\n",
    "train_score    0.971443\n",
    "test_score     0.962197\n",
    "\n",
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.4, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.943866    0.951362   0.947216\n",
    "severe_toxic   0.981002    0.987732   0.979689\n",
    "obscene        0.961675    0.967714   0.961563\n",
    "threat         0.948283    0.978424   0.950496\n",
    "insult         0.955456    0.963371   0.962704\n",
    "identity_hate  0.962063    0.978343   0.970227\n",
    "cv_score       0.958724\n",
    "train_score    0.971158\n",
    "test_score     0.961983\n",
    "\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'nb__alpha': 0.2, 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.15, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.943409    0.956741   0.948965\n",
    "severe_toxic   0.973072    0.985497   0.973623\n",
    "obscene        0.958114    0.969775    0.95988\n",
    "threat         0.912432    0.962793   0.919866\n",
    "insult         0.952491    0.966795   0.961544\n",
    "identity_hate  0.940987    0.970586   0.954784\n",
    "cv_score       0.946751\n",
    "train_score    0.968698\n",
    "test_score     0.953111\n",
    "\n",
    "              'tfidf__analyzer': ['char'],\\\n",
    "              'tfidf__max_df': [0.3, 0.2, 0.15],\\\n",
    "              'tfidf__min_df': [0.0001, 0.0003],\\\n",
    "              'tfidf__ngram_range': [(1,5)],\\\n",
    "              'tfidf__max_features': [40000],\\\n",
    "              'nb__alpha': [0.6, 0.4, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_mnb_full.to_csv('char_mnb_full.csv',index=False)\n",
    "char_mnb_records.to_csv('char_mnb_records.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **create train test sets for stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating out-of-sample predictions on identity_hate label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on insult label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on obscene label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on severe_toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on threat label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Wall time: 1h 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "char_mnb_stack_train = pd.DataFrame(np.zeros((n_train, 6)), columns=labels)\n",
    "char_mnb_stack_test = pd.read_csv('data/char_mnb_full.csv')[n_train:]\n",
    "char_mnb_records = pd.read_csv('data/char_mnb_records.csv')\n",
    "\n",
    "for j,label in enumerate(labels):\n",
    "    print('Start generating out-of-sample predictions on {} label for stacking'.format(label))\n",
    "    skf = list(StratifiedKFold(full_set[label][:n_train], 5))\n",
    "    char_mnb = Pipeline([('tfidf', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
    "    char_mnb.set_params(**ast.literal_eval(char_mnb_records.loc[j, 'best_params']))\n",
    "    for i,(train, test) in enumerate(skf):\n",
    "        print(\"Fold\", i+1)\n",
    "        X_train = full_set.cleaned_text[train]\n",
    "        y_train = full_set[label][train]\n",
    "        X_test = full_set.cleaned_text[test]\n",
    "        y_test = full_set[label][test]\n",
    "        char_mnb.fit(X_train, y_train)\n",
    "        char_mnb_stack_train.iloc[test, j] = char_mnb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.463650e-06</td>\n",
       "      <td>5.032522e-04</td>\n",
       "      <td>7.684948e-04</td>\n",
       "      <td>2.750926e-06</td>\n",
       "      <td>9.642752e-07</td>\n",
       "      <td>0.006465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.732348e-05</td>\n",
       "      <td>9.451995e-05</td>\n",
       "      <td>2.477398e-04</td>\n",
       "      <td>6.093440e-05</td>\n",
       "      <td>5.210060e-05</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.064627e-07</td>\n",
       "      <td>2.758274e-04</td>\n",
       "      <td>3.027401e-04</td>\n",
       "      <td>1.384921e-07</td>\n",
       "      <td>1.548660e-08</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.817968e-09</td>\n",
       "      <td>4.821126e-08</td>\n",
       "      <td>1.888385e-07</td>\n",
       "      <td>4.137550e-10</td>\n",
       "      <td>1.730474e-09</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.578316e-04</td>\n",
       "      <td>9.839470e-03</td>\n",
       "      <td>1.483689e-02</td>\n",
       "      <td>2.402789e-04</td>\n",
       "      <td>4.698432e-05</td>\n",
       "      <td>0.027643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>7.541756e-08</td>\n",
       "      <td>2.362018e-06</td>\n",
       "      <td>5.580502e-06</td>\n",
       "      <td>8.939188e-09</td>\n",
       "      <td>1.014323e-08</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>1.355518e-03</td>\n",
       "      <td>2.828723e-01</td>\n",
       "      <td>2.167588e-01</td>\n",
       "      <td>4.550665e-03</td>\n",
       "      <td>9.553775e-04</td>\n",
       "      <td>0.860932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>4.134106e-03</td>\n",
       "      <td>2.610219e-02</td>\n",
       "      <td>2.081535e-02</td>\n",
       "      <td>3.141605e-04</td>\n",
       "      <td>2.410661e-04</td>\n",
       "      <td>0.050555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>1.334546e-06</td>\n",
       "      <td>2.575844e-04</td>\n",
       "      <td>1.845466e-04</td>\n",
       "      <td>4.589477e-07</td>\n",
       "      <td>2.747028e-07</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>1.907155e-05</td>\n",
       "      <td>4.339068e-03</td>\n",
       "      <td>4.526867e-03</td>\n",
       "      <td>1.447689e-05</td>\n",
       "      <td>5.248774e-06</td>\n",
       "      <td>0.031091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        identity_hate        insult       obscene  severe_toxic        threat  \\\n",
       "0        3.463650e-06  5.032522e-04  7.684948e-04  2.750926e-06  9.642752e-07   \n",
       "1        8.732348e-05  9.451995e-05  2.477398e-04  6.093440e-05  5.210060e-05   \n",
       "2        3.064627e-07  2.758274e-04  3.027401e-04  1.384921e-07  1.548660e-08   \n",
       "3        9.817968e-09  4.821126e-08  1.888385e-07  4.137550e-10  1.730474e-09   \n",
       "4        7.578316e-04  9.839470e-03  1.483689e-02  2.402789e-04  4.698432e-05   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "159566   7.541756e-08  2.362018e-06  5.580502e-06  8.939188e-09  1.014323e-08   \n",
       "159567   1.355518e-03  2.828723e-01  2.167588e-01  4.550665e-03  9.553775e-04   \n",
       "159568   4.134106e-03  2.610219e-02  2.081535e-02  3.141605e-04  2.410661e-04   \n",
       "159569   1.334546e-06  2.575844e-04  1.845466e-04  4.589477e-07  2.747028e-07   \n",
       "159570   1.907155e-05  4.339068e-03  4.526867e-03  1.447689e-05  5.248774e-06   \n",
       "\n",
       "           toxic  \n",
       "0       0.006465  \n",
       "1       0.000321  \n",
       "2       0.003166  \n",
       "3       0.000001  \n",
       "4       0.027643  \n",
       "...          ...  \n",
       "159566  0.000044  \n",
       "159567  0.860932  \n",
       "159568  0.050555  \n",
       "159569  0.001428  \n",
       "159570  0.031091  \n",
       "\n",
       "[159571 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mnb_stack_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_mnb_stack_train.to_csv('data/char_mnb_stack_train.csv')\n",
    "char_mnb_stack_test.to_csv('data/char_mnb_stack_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
