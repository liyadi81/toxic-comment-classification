{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import ast\n",
    "\n",
    "pd.set_option(\"display.max_rows\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model from tfidf-word, all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_set = pd.read_pickle('full_cleaned.pkl')\n",
    "full_set_sw = pd.read_pickle('full_cleaned_sw.pkl')\n",
    "word2vec_model = Word2Vec.load('models/Myword2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training classifier on toxic label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 31.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}, cv_score: 0.9686441612554454, train_score: 0.9872585613774817, test_score: 0.9717791800531692\n",
      "Fitting final model and making prediction for submission on toxic label\n",
      "Start training classifier on severe_toxic label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 31.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}, cv_score: 0.9851474552431835, train_score: 0.9917170363946917, test_score: 0.9833844191221379\n",
      "Fitting final model and making prediction for submission on severe_toxic label\n",
      "Start training classifier on obscene label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 28.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}, cv_score: 0.9848137941650619, train_score: 0.9943263376125865, test_score: 0.9831182110502592\n",
      "Fitting final model and making prediction for submission on obscene label\n",
      "Start training classifier on threat label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 30.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 0.0001}, cv_score: 0.9811428041068667, train_score: 0.9973667522113111, test_score: 0.9736231038582817\n",
      "Fitting final model and making prediction for submission on threat label\n",
      "Start training classifier on insult label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 29.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}, cv_score: 0.9761933842973832, train_score: 0.9889081949539981, test_score: 0.9758932102834541\n",
      "Fitting final model and making prediction for submission on insult label\n",
      "Start training classifier on identity_hate label\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 30.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}, cv_score: 0.9727445487435387, train_score: 0.9927667679299728, test_score: 0.9790201632236318\n",
      "Fitting final model and making prediction for submission on identity_hate label\n",
      "Wall time: 3h 11min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_lg_records = pd.DataFrame(index=labels, columns=['best_params', 'cv_score', 'train_score', 'test_score'])\n",
    "word_lg_full = pd.DataFrame(index=full_set.index, columns=labels)\n",
    "for label in labels:\n",
    "    print('Start training classifier on {} label'.format(label))\n",
    "    x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(full_set.cleaned_text[:n_train], \n",
    "                                                        full_set[label][:n_train], \n",
    "                                                        np.arange(n_train),\n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state=2018,\n",
    "                                                        stratify = full_set[label][:n_train])\n",
    "    word_lg = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\n",
    "    parameters = {'tfidf__max_df': [0.5, 0.4, 0.2],\\\n",
    "                  'tfidf__min_df': [0.00005, 0.0001, 0.0002],\\\n",
    "                  'lg__class_weight': ['balanced'],\\\n",
    "                  'lg__solver': ['lbfgs'],\\\n",
    "                  'lg__C': [0.05, 0.1, 0.2, 0.4, 0.8, 1]\n",
    "                 }\n",
    "    word_lg_cv = GridSearchCV(word_lg, parameters, n_jobs=-1, scoring = 'roc_auc', verbose=1, cv=5)\n",
    "    word_lg_cv.fit(x_train, y_train)\n",
    "    word_lg_records.loc[label,'best_params'] = str(word_lg_cv.best_params_)\n",
    "    word_lg_records.loc[label,'cv_score'] = word_lg_cv.best_score_\n",
    "    word_lg_records.loc[label, 'train_score'] = metrics.roc_auc_score(y_train, word_lg_cv.predict_proba(x_train)[:,1])\n",
    "    word_lg_records.loc[label, 'test_score'] = metrics.roc_auc_score(y_test, word_lg_cv.predict_proba(x_test)[:,1])\n",
    "    print('Best params: {}, cv_score: {}, train_score: {}, test_score: {}'.format(*word_lg_records.loc[label]))\n",
    "    word_lg.set_params(**word_lg_cv.best_params_)\n",
    "    print('Fitting final model and making prediction for submission on {} label'.format(label))\n",
    "    word_lg.fit(full_set.cleaned_text[:n_train], full_set[label][:n_train])\n",
    "    word_lg_full[label] = word_lg.predict_proba(full_set.cleaned_text)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
      "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
      "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}\n",
      "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 0.0001}\n",
      "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}\n",
      "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
      "               cv_score train_score test_score\n",
      "toxic          0.968644    0.987259   0.971779\n",
      "severe_toxic   0.985147    0.991717   0.983384\n",
      "obscene        0.984814    0.994326   0.983118\n",
      "threat         0.981143    0.997367   0.973623\n",
      "insult         0.976193    0.988908   0.975893\n",
      "identity_hate  0.972745    0.992767    0.97902\n",
      "cv_score       0.978114\n",
      "train_score    0.992057\n",
      "test_score     0.977803\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(*word_lg_records.best_params, sep='\\n')\n",
    "print(word_lg_records.iloc[:,1:])\n",
    "print(word_lg_records.iloc[:,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001}\n",
    "               cv_score train_score test_score\n",
    "toxic           0.96785     0.98584   0.971031\n",
    "severe_toxic   0.984672    0.991401    0.98346\n",
    "obscene        0.984222    0.993775   0.981968\n",
    "threat         0.981143    0.997367   0.973623\n",
    "insult          0.97526    0.988024   0.975399\n",
    "identity_hate  0.971298    0.992237   0.978517\n",
    "cv_score       0.977407\n",
    "train_score    0.991440\n",
    "test_score     0.977333\n",
    "dtype: float64\n",
    "\n",
    "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
    "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}\n",
    "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 0.0001}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.2, 'tfidf__min_df': 5e-05}\n",
    "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__max_df': 0.5, 'tfidf__min_df': 5e-05}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.968644    0.987259   0.971779\n",
    "severe_toxic   0.985147    0.991717   0.983384\n",
    "obscene        0.984814    0.994326   0.983118\n",
    "threat         0.981143    0.997367   0.973623\n",
    "insult         0.976193    0.988908   0.975893\n",
    "identity_hate  0.972745    0.992767    0.97902\n",
    "cv_score       0.978114\n",
    "train_score    0.992057\n",
    "test_score     0.977803\n",
    "\n",
    "                  'tfidf__max_df': [0.5, 0.4, 0.3, 0.2],\\\n",
    "                  'tfidf__min_df': [0.00005, 0.0001, 0.0002, 0.0003, 0.001, 0.003],\\\n",
    "                  'lg__class_weight': ['balanced'],\\\n",
    "                  'lg__solver': ['lbfgs'],\\\n",
    "                  'lg__C': [0.05, 0.1, 0.2, 0.4, 0.8, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_lg_full.to_csv('word_lg_full.csv',index=False)\n",
    "word_lg_records.to_csv('word_lg_records.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model with tfidf-char, all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training classifier on toxic label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 104.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9688033831267864, train_score: 0.9923210747108505, test_score: 0.9725522185757541\n",
      "Fitting final model and making prediction for submission on toxic label\n",
      "Start training classifier on severe_toxic label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 71.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 99.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9872511038013121, train_score: 0.993530780682829, test_score: 0.9875079917659509\n",
      "Fitting final model and making prediction for submission on severe_toxic label\n",
      "Start training classifier on obscene label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 77.2min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 166.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9886951396500243, train_score: 0.9973444868645687, test_score: 0.988596326368802\n",
      "Fitting final model and making prediction for submission on obscene label\n",
      "Start training classifier on threat label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 82.1min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 111.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9761448347308186, train_score: 0.999219692732018, test_score: 0.9760630113558986\n",
      "Fitting final model and making prediction for submission on threat label\n",
      "Start training classifier on insult label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 87.7min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 123.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9778383091315479, train_score: 0.9935849276972556, test_score: 0.9778042816335499\n",
      "Fitting final model and making prediction for submission on insult label\n",
      "Start training classifier on identity_hate label\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 87.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 122.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}, cv_score: 0.9795780395096644, train_score: 0.9965552579050235, test_score: 0.9858488220588821\n",
      "Fitting final model and making prediction for submission on identity_hate label\n",
      "Wall time: 13h 26min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "char_lg_records = pd.DataFrame(index=labels, columns=['best_params', 'cv_score', 'train_score', 'test_score'])\n",
    "char_lg_full = pd.DataFrame(index=full_set.index, columns=labels)\n",
    "for label in labels:\n",
    "    print('Start training classifier on {} label'.format(label))\n",
    "    x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(full_set.cleaned_text[:n_train], \n",
    "                                                        full_set[label][:n_train], \n",
    "                                                        np.arange(n_train),\n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state=2018,\n",
    "                                                        stratify = full_set[label][:n_train])\n",
    "    char_lg = Pipeline([('tfidf', TfidfVectorizer()), ('lg', LogisticRegression())])\n",
    "    parameters = {'tfidf__analyzer': ['char'],\\\n",
    "              'tfidf__max_df': [0.4, 0.2],\\\n",
    "              'tfidf__min_df': [0.0001, 0.0003],\\\n",
    "              'tfidf__ngram_range': [(1,5)],\\\n",
    "#               'tfidf__max_features': [40000],\\\n",
    "              'lg__class_weight': ['balanced'],\\\n",
    "              'lg__solver': ['lbfgs'],\\\n",
    "              'lg__C': [0.1, 0.2, 0.4, 0.8, 1]\n",
    "                 }\n",
    "    char_lg_cv = GridSearchCV(char_lg, parameters, n_jobs=-1, scoring = 'roc_auc', verbose=1, cv=3)\n",
    "    char_lg_cv.fit(x_train, y_train)\n",
    "    char_lg_records.loc[label,'best_params'] = str(char_lg_cv.best_params_)\n",
    "    char_lg_records.loc[label,'cv_score'] = char_lg_cv.best_score_\n",
    "    char_lg_records.loc[label, 'train_score'] = metrics.roc_auc_score(y_train, char_lg_cv.predict_proba(x_train)[:,1])\n",
    "    char_lg_records.loc[label, 'test_score'] = metrics.roc_auc_score(y_test, char_lg_cv.predict_proba(x_test)[:,1])\n",
    "    print('Best params: {}, cv_score: {}, train_score: {}, test_score: {}'.format(*char_lg_records.loc[label]))\n",
    "    char_lg.set_params(**char_lg_cv.best_params_)\n",
    "    print('Fitting final model and making prediction for submission on {} label'.format(label))\n",
    "    char_lg.fit(full_set.cleaned_text[:n_train], full_set[label][:n_train])\n",
    "    char_lg_full[label] = char_lg.predict_proba(full_set.cleaned_text)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
      "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
      "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
      "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
      "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
      "               cv_score train_score test_score\n",
      "toxic          0.968803    0.992321   0.972552\n",
      "severe_toxic   0.987251    0.993531   0.987508\n",
      "obscene        0.988695    0.997344   0.988596\n",
      "threat         0.976145     0.99922   0.976063\n",
      "insult         0.977838    0.993585   0.977804\n",
      "identity_hate  0.979578    0.996555   0.985849\n",
      "cv_score       0.979718\n",
      "train_score    0.995426\n",
      "test_score     0.981395\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(*char_lg_records.best_params, sep='\\n')\n",
    "print(char_lg_records.iloc[:,1:])\n",
    "print(char_lg_records.iloc[:,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.4, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.8, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__max_features': 40000, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.967772    0.988358   0.971176\n",
    "severe_toxic   0.987057    0.992343    0.98716\n",
    "obscene        0.988175    0.996573   0.988169\n",
    "threat         0.975422    0.998486   0.976327\n",
    "insult         0.977073    0.991987   0.977095\n",
    "identity_hate  0.979267    0.996085   0.985326\n",
    "cv_score       0.979128\n",
    "train_score    0.993972\n",
    "test_score     0.980875\n",
    "dtype: float64\n",
    "\n",
    "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.2, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.4, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 1, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0001, 'tfidf__ngram_range': (1, 5)}\n",
    "{'lg__C': 0.4, 'lg__class_weight': 'balanced', 'lg__solver': 'lbfgs', 'tfidf__analyzer': 'char', 'tfidf__max_df': 0.2, 'tfidf__min_df': 0.0003, 'tfidf__ngram_range': (1, 5)}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.968803    0.992321   0.972552\n",
    "severe_toxic   0.987251    0.993531   0.987508\n",
    "obscene        0.988695    0.997344   0.988596\n",
    "threat         0.976145     0.99922   0.976063\n",
    "insult         0.977838    0.993585   0.977804\n",
    "identity_hate  0.979578    0.996555   0.985849\n",
    "cv_score       0.979718\n",
    "train_score    0.995426\n",
    "test_score     0.981395\n",
    "\n",
    "              'tfidf__analyzer': ['char'],\\\n",
    "              'tfidf__max_df': [0.4, 0.2],\\\n",
    "              'tfidf__min_df': [0.0001],\\\n",
    "              'tfidf__ngram_range': [(1,5)],\\\n",
    "              'tfidf__max_features': [40000],\\\n",
    "              'lg__class_weight': ['balanced'],\\\n",
    "              'lg__solver': ['lbfgs'],\\\n",
    "              'lg__C': [0.1, 0.2, 0.4, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_lg_full.to_csv('char_lg_full.csv',index=False)\n",
    "char_lg_records.to_csv('char_lg_records.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression model with word2vec, all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_comment_vect(comment_column):\n",
    "    return(np.array([np.mean([word2vec_model.wv.word_vec(word) \n",
    "                              for word in comment.split() if word in word2vec_model.wv.vocab] \n",
    "                             or [np.zeros(300)], axis=0) \n",
    "                     for comment in comment_column]\n",
    "                   ))\n",
    "comment_vect = pd.DataFrame(get_comment_vect(full_set_sw.cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training classifier on toxic label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.3, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.9596047524368049, train_score: 0.9621766444419689, test_score: 0.9625495850799717\n",
      "Fitting final model and making prediction for submission on toxic label\n",
      "Start training classifier on severe_toxic label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.9829759387488306, train_score: 0.9855514617060257, test_score: 0.9818582944311431\n",
      "Fitting final model and making prediction for submission on severe_toxic label\n",
      "Start training classifier on obscene label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.9716778450816964, train_score: 0.9749443268377088, test_score: 0.9706400418948615\n",
      "Fitting final model and making prediction for submission on obscene label\n",
      "Start training classifier on threat label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.9775136135931969, train_score: 0.9867680969787161, test_score: 0.9751129762615628\n",
      "Fitting final model and making prediction for submission on threat label\n",
      "Start training classifier on insult label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.9675018756965723, train_score: 0.9705305976921453, test_score: 0.9692536752780653\n",
      "Fitting final model and making prediction for submission on insult label\n",
      "Start training classifier on identity_hate label\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}, cv_score: 0.960261719137092, train_score: 0.9681775813986767, test_score: 0.9641517066753486\n",
      "Fitting final model and making prediction for submission on identity_hate label\n",
      "Wall time: 19min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2v_lg_records = pd.DataFrame(index=labels, columns=['best_params', 'cv_score', 'train_score', 'test_score'])\n",
    "w2v_lg_full = pd.DataFrame(index=full_set.index, columns=labels)\n",
    "for label in labels:\n",
    "    print('Start training classifier on {} label'.format(label))\n",
    "    x_train, x_test, y_train, y_test, train_idx, test_idx = train_test_split(comment_vect[:n_train], \n",
    "                                                        full_set_sw[label][:n_train], \n",
    "                                                        np.arange(n_train),\n",
    "                                                        test_size = 0.2, \n",
    "                                                        random_state=2018,\n",
    "                                                        stratify = full_set_sw[label][:n_train])\n",
    "    w2v_lg = LogisticRegression()\n",
    "    parameters = {'class_weight': ['balanced'],\\\n",
    "                  'solver': ['lbfgs'],\\\n",
    "                  'C': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "                 }\n",
    "    w2v_lg_cv = GridSearchCV(w2v_lg, parameters, n_jobs=-1, scoring = 'roc_auc', verbose=5, cv=5)\n",
    "    w2v_lg_cv.fit(x_train, y_train)\n",
    "    w2v_lg_records.loc[label,'best_params'] = str(w2v_lg_cv.best_params_)\n",
    "    w2v_lg_records.loc[label,'cv_score'] = w2v_lg_cv.best_score_\n",
    "    w2v_lg_records.loc[label, 'train_score'] = metrics.roc_auc_score(y_train, w2v_lg_cv.predict_proba(x_train)[:,1])\n",
    "    w2v_lg_records.loc[label, 'test_score'] = metrics.roc_auc_score(y_test, w2v_lg_cv.predict_proba(x_test)[:,1])\n",
    "    print('Best params: {}, cv_score: {}, train_score: {}, test_score: {}'.format(*w2v_lg_records.loc[label]))\n",
    "    w2v_lg.set_params(**w2v_lg_cv.best_params_)\n",
    "    print('Fitting final model and making prediction for submission on {} label'.format(label))\n",
    "    w2v_lg.fit(comment_vect[:n_train], full_set_sw[label][:n_train])\n",
    "    w2v_lg_full[label] = w2v_lg.predict_proba(comment_vect)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.3, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "               cv_score train_score test_score\n",
      "toxic          0.959605    0.962177    0.96255\n",
      "severe_toxic   0.982976    0.985551   0.981858\n",
      "obscene        0.971678    0.974944    0.97064\n",
      "threat         0.977514    0.986768   0.975113\n",
      "insult         0.967502    0.970531   0.969254\n",
      "identity_hate  0.960262    0.968178   0.964152\n",
      "cv_score       0.969923\n",
      "train_score    0.974691\n",
      "test_score     0.970594\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(*w2v_lg_records.best_params, sep='\\n')\n",
    "print(w2v_lg_records.iloc[:,1:])\n",
    "print(w2v_lg_records.iloc[:,1:].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec: size=300, window=5\n",
    "{'C': 0.3, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "               cv_score train_score test_score\n",
    "toxic          0.959605    0.962177    0.96255\n",
    "severe_toxic   0.982976    0.985551   0.981858\n",
    "obscene        0.971678    0.974944    0.97064\n",
    "threat         0.977514    0.986768   0.975113\n",
    "insult         0.967502    0.970531   0.969254\n",
    "identity_hate  0.960262    0.968178   0.964152\n",
    "cv_score       0.969923\n",
    "train_score    0.974691\n",
    "test_score     0.970594\n",
    "\n",
    "word2vec: size=100, window=3\n",
    "{'C': 1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 10, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.1, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "{'C': 0.01, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
    "               cv_score train_score test_score\n",
    "toxic           0.95375    0.954787   0.957034\n",
    "severe_toxic     0.9822    0.983757   0.982192\n",
    "obscene        0.964333    0.965793   0.966064\n",
    "threat          0.97269    0.979577   0.972365\n",
    "insult         0.963145    0.964357   0.964598\n",
    "identity_hate  0.957263    0.961801   0.959968\n",
    "cv_score       0.965564\n",
    "train_score    0.968345\n",
    "test_score     0.967037\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_lg_full.to_csv('w2v_lg_full.csv',index=False)\n",
    "w2v_lg_records.to_csv('w2v_lg_records.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create train test sets for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generating out-of-sample predictions on toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on severe_toxic label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on obscene label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on threat label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on insult label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Start generating out-of-sample predictions on identity_hate label for stacking\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2v_lg_stack_train = pd.DataFrame(np.zeros((n_train, 6)), columns=labels)\n",
    "w2v_lg_stack_test = pd.read_csv('w2v_lg_full.csv')[n_train:]\n",
    "w2v_lg_records = pd.read_csv('w2v_lg_records.csv')\n",
    "\n",
    "for j,label in enumerate(labels):\n",
    "    print('Start generating out-of-sample predictions on {} label for stacking'.format(label))\n",
    "    skf = list(StratifiedKFold(full_set_sw[label][:n_train], 5))\n",
    "    w2v_lg = LogisticRegression(**ast.literal_eval(w2v_lg_records.loc[j, 'best_params']))\n",
    "    for i,(train, test) in enumerate(skf):\n",
    "        print(\"Fold\", i+1)\n",
    "        X_train = comment_vect.iloc[train,:]\n",
    "        y_train = full_set_sw[label][train]\n",
    "        X_test = comment_vect.iloc[test,:]\n",
    "        y_test = full_set_sw[label][test]\n",
    "        w2v_lg.fit(X_train, y_train)\n",
    "        w2v_lg_stack_train.iloc[test, j] = w2v_lg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_lg_stack_train.to_csv('w2v_lg_stack_train.csv')\n",
    "w2v_lg_stack_test.to_csv('w2v_lg_stack_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
